
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Framework agnostic Bayesian Neural Network library" name="description"/>
<link href="losses.html" rel="prev"/>
<link href="../Tensorflow/distributions.html" rel="next"/>
<link href="../../../assets/images/white_logo_illia.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.16" name="generator"/>
<title>Neural Network - illia</title>
<link href="../../../assets/stylesheets/main.7e37652d.min.css" rel="stylesheet"/>
<link href="../../../assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../../assets/css/custom.css" rel="stylesheet"/>
<script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
</head>
<body data-md-color-accent="black" data-md-color-primary="black" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#neural-network">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<div data-md-color-scheme="default" data-md-component="outdated" hidden="">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="illia" class="md-header__button md-logo" data-md-component="logo" href="../../../index.html" title="illia">
<img alt="logo" src="../../../assets/images/white_logo_illia.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            illia
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Neural Network
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="black" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="black" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="black" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
<div class="md-search__suggest" data-md-component="search-suggest"></div>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/EricssonResearch/illia" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    EricssonResearch/illia
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../index.html">
        
  
  
    
  
  Home

      </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../Jax/distributions.html">
          
  
  
    
  
  API

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../examples/Computer%20Vision/MNIST%20Bayesian%20CNN.html">
          
  
  
    
  
  Examples

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../reference/bayesian_neural_networks.html">
          
  
  
    
  
  Reference

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="https://ericsson.github.io/cognitive-labs/">
        
  
  
    
  
  Ericsson Cognitive Labs

      </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="illia" class="md-nav__button md-logo" data-md-component="logo" href="../../../index.html" title="illia">
<img alt="logo" src="../../../assets/images/white_logo_illia.png"/>
</a>
    illia
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/EricssonResearch/illia" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2" fill="currentColor"></path></svg>
</div>
<div class="md-source__repository">
    EricssonResearch/illia
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../index.html">
<span class="md-ellipsis">
    Home
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
<span class="md-ellipsis">
    API
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
            API
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_2_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="">
<span class="md-ellipsis">
    Deep Learning
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_2_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_1">
<span class="md-nav__icon md-icon"></span>
            Deep Learning
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_1_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_1_1" id="__nav_2_1_1_label" tabindex="0">
<span class="md-ellipsis">
    Jax
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_1_1_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_2_1_1">
<span class="md-nav__icon md-icon"></span>
            Jax
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../Jax/distributions.html">
<span class="md-ellipsis">
    Distributions
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Jax/losses.html">
<span class="md-ellipsis">
    Losses
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Jax/nn.html">
<span class="md-ellipsis">
    Neural Network
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_2_1_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_1_2" id="__nav_2_1_2_label" tabindex="0">
<span class="md-ellipsis">
    PyTorch
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_2_1_2_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_2_1_2">
<span class="md-nav__icon md-icon"></span>
            PyTorch
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="distributions.html">
<span class="md-ellipsis">
    Distributions
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="losses.html">
<span class="md-ellipsis">
    Losses
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    Neural Network
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="nn.html">
<span class="md-ellipsis">
    Neural Network
    
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.conv1d">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-module"></code> conv1d
    </span>
</a>
<nav aria-label=" conv1d" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.conv1d.Conv1D">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> Conv1D
    </span>
</a>
<nav aria-label=" Conv1D" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.conv1d.Conv1D.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> forward
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.conv1d.Conv1D.freeze">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> freeze
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.conv1d.Conv1D.kl_cost">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> kl_cost
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.conv2d">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-module"></code> conv2d
    </span>
</a>
<nav aria-label=" conv2d" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.conv2d.Conv2D">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> Conv2D
    </span>
</a>
<nav aria-label=" Conv2D" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.conv2d.Conv2D.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> forward
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.conv2d.Conv2D.freeze">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> freeze
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.conv2d.Conv2D.kl_cost">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> kl_cost
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.embedding">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-module"></code> embedding
    </span>
</a>
<nav aria-label=" embedding" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.embedding.Embedding">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> Embedding
    </span>
</a>
<nav aria-label=" Embedding" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.embedding.Embedding.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> forward
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.embedding.Embedding.freeze">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> freeze
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.embedding.Embedding.kl_cost">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> kl_cost
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.linear">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-module"></code> linear
    </span>
</a>
<nav aria-label=" linear" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.linear.Linear">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-class"></code> Linear
    </span>
</a>
<nav aria-label=" Linear" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.linear.Linear.forward">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> forward
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.linear.Linear.freeze">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> freeze
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#illia.nn.torch.linear.Linear.kl_cost">
<span class="md-ellipsis">
<code class="doc-symbol doc-symbol-toc doc-symbol-method"></code> kl_cost
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_1_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_1_3" id="__nav_2_1_3_label" tabindex="0">
<span class="md-ellipsis">
    Tensorflow
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_1_3_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_2_1_3">
<span class="md-nav__icon md-icon"></span>
            Tensorflow
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../Tensorflow/distributions.html">
<span class="md-ellipsis">
    Distributions
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Tensorflow/losses.html">
<span class="md-ellipsis">
    Losses
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../Tensorflow/nn.html">
<span class="md-ellipsis">
    Neural Network
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="">
<span class="md-ellipsis">
    Geometric Deep Learning
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_2_2">
<span class="md-nav__icon md-icon"></span>
            Geometric Deep Learning
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2_2_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_2_2_1" id="__nav_2_2_1_label" tabindex="0">
<span class="md-ellipsis">
    PyG
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_2_1_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_2_2_1">
<span class="md-nav__icon md-icon"></span>
            PyG
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../Geometric%20Deep%20Learning/PyG/nn.html">
<span class="md-ellipsis">
    Neural Network
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
<span class="md-ellipsis">
    Examples
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            Examples
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
<span class="md-ellipsis">
    Computer Vision
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_1">
<span class="md-nav__icon md-icon"></span>
            Computer Vision
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/Computer%20Vision/MNIST%20Bayesian%20CNN.html">
<span class="md-ellipsis">
    MNIST Bayesian CNN
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
<span class="md-ellipsis">
    Reference
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
            Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../reference/bayesian_neural_networks.html">
<span class="md-ellipsis">
    Bayesian Neural Networks
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../reference/bibliography.html">
<span class="md-ellipsis">
    Bibliography
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="https://ericsson.github.io/cognitive-labs/">
<span class="md-ellipsis">
    Ericsson Cognitive Labs
    
  </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<h1 id="neural-network"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.</span> Neural Network</h1>
<div class="doc doc-object doc-module">
<h2 class="doc doc-heading" id="illia.nn.torch.conv1d"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.1</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code> <code>conv1d</code>
</h2>
<div class="doc doc-contents first">
<p>This module contains the code for the bayesian Conv1D.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="illia.nn.torch.conv1d.Conv1D"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.1.1</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <code class="highlight language-python"><span class="n">Conv1D</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">weights_distribution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias_distribution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>
</h3>
<div class="doc doc-contents">
<p>This class is the bayesian implementation of the Conv1D class.</p>
<p>Definition of a Bayesian Convolution 1D layer.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>input_channels</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of channels in the input image.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>output_channels</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of channels produced by the
convolution.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>kernel_size</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Size of the convolving kernel.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>stride</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Stride of the convolution. Deafults to 1.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>padding</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Padding added to all four sides of the input.
Defaults to 0.</p>
</div>
</td>
<td>
<code>0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>dilation</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Spacing between kernel elements.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>groups</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of blocked connections from input channels
to output channels. Defaults to 1.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>weights_distribution</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" href="distributions.html#illia.distributions.torch.gaussian.GaussianDistribution">GaussianDistribution</a>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The distribution for the weights.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bias_distribution</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" href="distributions.html#illia.distributions.torch.gaussian.GaussianDistribution">GaussianDistribution</a>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The distribution for the bias.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/conv1d.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">output_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">weights_distribution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GaussianDistribution</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bias_distribution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GaussianDistribution</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Definition of a Bayesian Convolution 1D layer.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_channels: Number of channels in the input image.</span>
<span class="sd">        output_channels: Number of channels produced by the</span>
<span class="sd">            convolution.</span>
<span class="sd">        kernel_size: Size of the convolving kernel.</span>
<span class="sd">        stride: Stride of the convolution. Deafults to 1.</span>
<span class="sd">        padding: Padding added to all four sides of the input.</span>
<span class="sd">            Defaults to 0.</span>
<span class="sd">        dilation: Spacing between kernel elements.</span>
<span class="sd">        groups: Number of blocked connections from input channels</span>
<span class="sd">            to output channels. Defaults to 1.</span>
<span class="sd">        weights_distribution: The distribution for the weights.</span>
<span class="sd">        bias_distribution: The distribution for the bias.</span>
<span class="sd">    """</span>

    <span class="c1"># Call super class constructor</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Set attributes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>

    <span class="c1"># Set weights distribution</span>
    <span class="k">if</span> <span class="n">weights_distribution</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Define weights distribution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span> <span class="o">=</span> <span class="n">GaussianDistribution</span><span class="p">(</span>
            <span class="p">(</span><span class="n">output_channels</span><span class="p">,</span> <span class="n">input_channels</span> <span class="o">//</span> <span class="n">groups</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span> <span class="o">=</span> <span class="n">weights_distribution</span>

    <span class="c1"># Set bias distribution</span>
    <span class="k">if</span> <span class="n">bias_distribution</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Define weights distribution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span> <span class="o">=</span> <span class="n">GaussianDistribution</span><span class="p">((</span><span class="n">output_channels</span><span class="p">,))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span> <span class="o">=</span> <span class="n">bias_distribution</span>

    <span class="c1"># Sample initial weights</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Register buffers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"weights"</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"bias"</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.conv1d.Conv1D.forward"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.1.1.1</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>
</h4>
<div class="doc doc-contents">
<p>Performs a forward pass through the Bayesian Convolution 2D
layer. If the layer is not frozen, it samples weights and bias
from their respective distributions. If the layer is frozen
and the weights or bias are not initialized, it also performs
sampling.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>inputs</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Input tensor to the layer. Dimensions: [batch,
input channels, input width, input height].</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Output tensor after passing through the layer. Dimensions:
[batch, output channels, output width, output height].</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/conv1d.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Performs a forward pass through the Bayesian Convolution 2D</span>
<span class="sd">    layer. If the layer is not frozen, it samples weights and bias</span>
<span class="sd">    from their respective distributions. If the layer is frozen</span>
<span class="sd">    and the weights or bias are not initialized, it also performs</span>
<span class="sd">    sampling.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs: Input tensor to the layer. Dimensions: [batch,</span>
<span class="sd">            input channels, input width, input height].</span>

<span class="sd">    Returns:</span>
<span class="sd">        Output tensor after passing through the layer. Dimensions:</span>
<span class="sd">            [batch, output channels, output width, output height].</span>
<span class="sd">    """</span>

    <span class="c1"># Forward depending of frozen state</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Module has been frozen with undefined weights"</span><span class="p">)</span>

    <span class="c1"># Execute torch forward</span>
    <span class="c1"># pylint: disable=E1102</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">conv1d</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_params</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.conv1d.Conv1D.freeze"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.1.1.2</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">freeze</span><span class="p">()</span></code>
</h4>
<div class="doc doc-contents">
<p>Freezes the current module and all submodules that are instances
of BayesianModule. Sets the frozen state to True.</p>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/conv1d.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
<span class="k">def</span><span class="w"> </span><span class="nf">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Freezes the current module and all submodules that are instances</span>
<span class="sd">    of BayesianModule. Sets the frozen state to True.</span>
<span class="sd">    """</span>

    <span class="c1"># Set indicator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Sample weights if they are undefined</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Sample bias is they are undefined</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Detach weights and bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.conv1d.Conv1D.kl_cost"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.1.1.3</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">kl_cost</span><span class="p">()</span></code>
</h4>
<div class="doc doc-contents">
<p>Computes the Kullback-Leibler (KL) divergence cost for the
layer's weights and bias.</p>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Tuple containing KL divergence cost and total number of</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>parameters.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/conv1d.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kl_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Computes the Kullback-Leibler (KL) divergence cost for the</span>
<span class="sd">    layer's weights and bias.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple containing KL divergence cost and total number of</span>
<span class="sd">        parameters.</span>
<span class="sd">    """</span>

    <span class="c1"># Compute log probs</span>
    <span class="n">log_probs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
    <span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="c1"># Compute number of parameters</span>
    <span class="n">num_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">num_params</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">num_params</span><span class="p">()</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">num_params</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h2 class="doc doc-heading" id="illia.nn.torch.conv2d"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.2</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code> <code>conv2d</code>
</h2>
<div class="doc doc-contents first">
<p>This module contains the code for the bayesian Conv2D.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="illia.nn.torch.conv2d.Conv2D"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.2.1</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <code class="highlight language-python"><span class="n">Conv2D</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">weights_distribution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias_distribution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>
</h3>
<div class="doc doc-contents">
<p>This class is the bayesian implementation of the Conv2D class.</p>
<p>Definition of a Bayesian Convolution 2D layer.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>kernel_size</code>
</td>
<td>
<code><span title="int">int</span> | <span title="tuple">tuple</span>[<span title="int">int</span>, <span title="int">int</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Size of the convolving kernel.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>stride</code>
</td>
<td>
<code><span title="int">int</span> | <span title="tuple">tuple</span>[<span title="int">int</span>, <span title="int">int</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Stride of the convolution. Deafults to 1.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>padding</code>
</td>
<td>
<code><span title="int">int</span> | <span title="tuple">tuple</span>[<span title="int">int</span>, <span title="int">int</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Padding added to all four sides of the input.</p>
</div>
</td>
<td>
<code>0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>dilation</code>
</td>
<td>
<code><span title="int">int</span> | <span title="tuple">tuple</span>[<span title="int">int</span>, <span title="int">int</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>Spacing between kernel elements.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>groups</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Number of blocked connections from input channels
to output channels.</p>
</div>
</td>
<td>
<code>1</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>weights_distribution</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" href="distributions.html#illia.distributions.torch.gaussian.GaussianDistribution">GaussianDistribution</a>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The distribution for the weights.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bias_distribution</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" href="distributions.html#illia.distributions.torch.gaussian.GaussianDistribution">GaussianDistribution</a>]</code>
</td>
<td>
<div class="doc-md-description">
<p>The distribution for the bias.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/conv2d.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">output_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">weights_distribution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GaussianDistribution</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bias_distribution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GaussianDistribution</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Definition of a Bayesian Convolution 2D layer.</span>

<span class="sd">    Args:</span>
<span class="sd">        kernel_size: Size of the convolving kernel.</span>
<span class="sd">        stride: Stride of the convolution. Deafults to 1.</span>
<span class="sd">        padding: Padding added to all four sides of the input.</span>
<span class="sd">        dilation: Spacing between kernel elements.</span>
<span class="sd">        groups: Number of blocked connections from input channels</span>
<span class="sd">            to output channels.</span>
<span class="sd">        weights_distribution: The distribution for the weights.</span>
<span class="sd">        bias_distribution: The distribution for the bias.</span>
<span class="sd">    """</span>

    <span class="c1"># Call super class constructor</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Set attributes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span> <span class="o">=</span> <span class="n">input_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span> <span class="o">=</span> <span class="n">output_channels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stride</span> <span class="o">=</span> <span class="n">stride</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">padding</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="n">dilation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">groups</span> <span class="o">=</span> <span class="n">groups</span>

    <span class="c1"># Set weights distribution</span>
    <span class="k">if</span> <span class="n">weights_distribution</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Extend kernel if we only have 1 value</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">)</span>

        <span class="c1"># Define weights distribution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span> <span class="o">=</span> <span class="n">GaussianDistribution</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">input_channels</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
                <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span> <span class="o">=</span> <span class="n">weights_distribution</span>

    <span class="c1"># Set bias distribution</span>
    <span class="k">if</span> <span class="n">bias_distribution</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Define weights distribution</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span> <span class="o">=</span> <span class="n">GaussianDistribution</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">output_channels</span><span class="p">,))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span> <span class="o">=</span> <span class="n">bias_distribution</span>

    <span class="c1"># Sample initial weights</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Register buffers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"weights"</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"bias"</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.conv2d.Conv2D.forward"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.2.1.1</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>
</h4>
<div class="doc doc-contents">
<p>Performs a forward pass through the Bayesian Convolution 2D
layer. If the layer is not frozen, it samples weights and bias
from their respective distributions. If the layer is frozen
and the weights or bias are not initialized, it also performs
sampling.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>inputs</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Input tensor to the layer. Dimensions: [batch,
input channels, input width, input height].</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Output tensor after passing through the layer. Dimensions:
[batch, output channels, output width, output height].</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/conv2d.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Performs a forward pass through the Bayesian Convolution 2D</span>
<span class="sd">    layer. If the layer is not frozen, it samples weights and bias</span>
<span class="sd">    from their respective distributions. If the layer is frozen</span>
<span class="sd">    and the weights or bias are not initialized, it also performs</span>
<span class="sd">    sampling.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs: Input tensor to the layer. Dimensions: [batch,</span>
<span class="sd">            input channels, input width, input height].</span>

<span class="sd">    Returns:</span>
<span class="sd">        Output tensor after passing through the layer. Dimensions:</span>
<span class="sd">            [batch, output channels, output width, output height].</span>
<span class="sd">    """</span>

    <span class="c1"># Forward depending of frozen state</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Execute torch forward</span>
    <span class="c1"># pylint: disable=E1102</span>
    <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
        <span class="n">weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">dilation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">groups</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.conv2d.Conv2D.freeze"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.2.1.2</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">freeze</span><span class="p">()</span></code>
</h4>
<div class="doc doc-contents">
<p>Freezes the current module and all submodules that are instances
of BayesianModule. Sets the frozen state to True.</p>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/conv2d.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
<span class="k">def</span><span class="w"> </span><span class="nf">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Freezes the current module and all submodules that are instances</span>
<span class="sd">    of BayesianModule. Sets the frozen state to True.</span>
<span class="sd">    """</span>

    <span class="c1"># Set indicator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Sample weights if they are undefined</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Sample bias is they are undefined</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Detach weights and bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.conv2d.Conv2D.kl_cost"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.2.1.3</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">kl_cost</span><span class="p">()</span></code>
</h4>
<div class="doc doc-contents">
<p>Computes the Kullback-Leibler (KL) divergence cost for the
layer's weights and bias.</p>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Tuple containing KL divergence cost and total number of</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>parameters.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/conv2d.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kl_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Computes the Kullback-Leibler (KL) divergence cost for the</span>
<span class="sd">    layer's weights and bias.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple containing KL divergence cost and total number of</span>
<span class="sd">        parameters.</span>
<span class="sd">    """</span>

    <span class="c1"># Compute log probs</span>
    <span class="n">log_probs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
    <span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="c1"># Compute number of parameters</span>
    <span class="n">num_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">num_params</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">num_params</span><span class="p">()</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">num_params</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h2 class="doc doc-heading" id="illia.nn.torch.embedding"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.3</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code> <code>embedding</code>
</h2>
<div class="doc doc-contents first">
<p>This module contains the code for bayesian Embedding layer.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="illia.nn.torch.embedding.Embedding"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.3.1</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <code class="highlight language-python"><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embeddings_dim</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">weights_distribution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>
</h3>
<div class="doc doc-contents">
<p>This class is the bayesian implementation of the Embedding class.</p>
<p>This method is the constructor of the embedding class.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>num_embeddings</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>size of the dictionary of embeddings.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>embeddings_dim</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>the size of each embedding vector.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>padding_idx</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="int">int</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>If specified, the entries at padding_idx do
not contribute to the gradient.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>max_norm</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<span title="float">float</span>]</code>
</td>
<td>
<div class="doc-md-description">
<p>If given, each embedding vector with norm larger
than max_norm is renormalized to have norm max_norm.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>norm_type</code>
</td>
<td>
<code><span title="float">float</span></code>
</td>
<td>
<div class="doc-md-description">
<p>The p of the p-norm to compute for the max_norm
option.</p>
</div>
</td>
<td>
<code>2.0</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>scale_grad_by_freq</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If given, this will scale gradients by
the inverse of frequency of the words in the
mini-batch.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>sparse</code>
</td>
<td>
<code><span title="bool">bool</span></code>
</td>
<td>
<div class="doc-md-description">
<p>If True, gradient w.r.t. weight matrix will be a
sparse tensor.</p>
</div>
</td>
<td>
<code>False</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>weights_distribution</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" href="distributions.html#illia.distributions.torch.gaussian.GaussianDistribution">GaussianDistribution</a>]</code>
</td>
<td>
<div class="doc-md-description">
<p>distribution for the weights of the
layer.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/embedding.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_embeddings</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">embeddings_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">padding_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">norm_type</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span>
    <span class="n">scale_grad_by_freq</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">sparse</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">weights_distribution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GaussianDistribution</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This method is the constructor of the embedding class.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_embeddings: size of the dictionary of embeddings.</span>
<span class="sd">        embeddings_dim: the size of each embedding vector.</span>
<span class="sd">        padding_idx: If specified, the entries at padding_idx do</span>
<span class="sd">            not contribute to the gradient.</span>
<span class="sd">        max_norm: If given, each embedding vector with norm larger</span>
<span class="sd">            than max_norm is renormalized to have norm max_norm.</span>
<span class="sd">        norm_type: The p of the p-norm to compute for the max_norm</span>
<span class="sd">            option.</span>
<span class="sd">        scale_grad_by_freq: If given, this will scale gradients by</span>
<span class="sd">            the inverse of frequency of the words in the</span>
<span class="sd">            mini-batch.</span>
<span class="sd">        sparse: If True, gradient w.r.t. weight matrix will be a</span>
<span class="sd">            sparse tensor.</span>
<span class="sd">        weights_distribution: distribution for the weights of the</span>
<span class="sd">            layer.</span>
<span class="sd">    """</span>

    <span class="c1"># Call super class constructor</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Set embeddings atributtes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding_params</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">padding_idx</span><span class="p">,</span>
        <span class="n">max_norm</span><span class="p">,</span>
        <span class="n">norm_type</span><span class="p">,</span>
        <span class="n">scale_grad_by_freq</span><span class="p">,</span>
        <span class="n">sparse</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Set weights distribution</span>
    <span class="k">if</span> <span class="n">weights_distribution</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span> <span class="o">=</span> <span class="n">GaussianDistribution</span><span class="p">(</span>
            <span class="p">(</span><span class="n">num_embeddings</span><span class="p">,</span> <span class="n">embeddings_dim</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span> <span class="o">=</span> <span class="n">weights_distribution</span>

    <span class="c1"># Sample initial weights</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Register buffers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"weights"</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.embedding.Embedding.forward"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.3.1.1</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>
</h4>
<div class="doc doc-contents">
<p>This method is the forward pass of the layer.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>inputs</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>input tensor. Dimensions: [*].</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="ValueError">ValueError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Module has been frozen with undefined weights.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>outputs tensor. Dimension: [*, embedding dim].</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/embedding.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This method is the forward pass of the layer.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs: input tensor. Dimensions: [*].</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: Module has been frozen with undefined weights.</span>

<span class="sd">    Returns:</span>
<span class="sd">        outputs tensor. Dimension: [*, embedding dim].</span>
<span class="sd">    """</span>

    <span class="c1"># Forward depeding of frozen state</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Module has been frozen with undefined weights"</span><span class="p">)</span>

    <span class="c1"># Run torch forward</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_params</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.embedding.Embedding.freeze"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.3.1.2</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">freeze</span><span class="p">()</span></code>
</h4>
<div class="doc doc-contents">
<p>Freezes the current module and all submodules that are instances
of BayesianModule. Sets the frozen state to True.</p>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/embedding.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span>
<span class="normal">97</span>
<span class="normal">98</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
<span class="k">def</span><span class="w"> </span><span class="nf">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Freezes the current module and all submodules that are instances</span>
<span class="sd">    of BayesianModule. Sets the frozen state to True.</span>
<span class="sd">    """</span>

    <span class="c1"># set indicator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># sample weights if they are undefined</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># detach weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.embedding.Embedding.kl_cost"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.3.1.3</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">kl_cost</span><span class="p">()</span></code>
</h4>
<div class="doc doc-contents">
<p>Computes the Kullback-Leibler (KL) divergence cost for the
layer's weights and bias.</p>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Tuple containing KL divergence cost and total number of</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>parameters.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/embedding.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kl_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Computes the Kullback-Leibler (KL) divergence cost for the</span>
<span class="sd">    layer's weights and bias.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple containing KL divergence cost and total number of</span>
<span class="sd">        parameters.</span>
<span class="sd">    """</span>

    <span class="c1"># get log posterior and log prior</span>
    <span class="n">log_probs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># get number of parameters</span>
    <span class="n">num_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">num_params</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">num_params</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-module">
<h2 class="doc doc-heading" id="illia.nn.torch.linear"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.4</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code> <code>linear</code>
</h2>
<div class="doc doc-contents first">
<p>This module contains the code for Linear Bayesian layer.</p>
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="illia.nn.torch.linear.Linear"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.4.1</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code> <code class="highlight language-python"><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">weights_distribution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias_distribution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>
</h3>
<div class="doc doc-contents">
<p>This class is the bayesian implementation of the torch Linear layer.</p>
<p>This is the constructor of the Linear class.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>input_size</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Input size of the linear layer.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>output_size</code>
</td>
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Output size of the linear layer.</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>weights_distribution</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" href="distributions.html#illia.distributions.torch.gaussian.GaussianDistribution">GaussianDistribution</a>]</code>
</td>
<td>
<div class="doc-md-description">
<p>GaussianDistribution for the weights of the
layer. Defaults to None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code>bias_distribution</code>
</td>
<td>
<code><span title="typing.Optional">Optional</span>[<a class="autorefs autorefs-internal" href="distributions.html#illia.distributions.torch.gaussian.GaussianDistribution">GaussianDistribution</a>]</code>
</td>
<td>
<div class="doc-md-description">
<p>GaussianDistribution for the bias of the layer.
Defaults to None.</p>
</div>
</td>
<td>
<code>None</code>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/linear.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">output_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">weights_distribution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GaussianDistribution</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bias_distribution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">GaussianDistribution</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This is the constructor of the Linear class.</span>

<span class="sd">    Args:</span>
<span class="sd">        input_size: Input size of the linear layer.</span>
<span class="sd">        output_size: Output size of the linear layer.</span>
<span class="sd">        weights_distribution: GaussianDistribution for the weights of the</span>
<span class="sd">            layer. Defaults to None.</span>
<span class="sd">        bias_distribution: GaussianDistribution for the bias of the layer.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">    """</span>

    <span class="c1"># Call super-class constructor</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># Set weights distribution</span>
    <span class="k">if</span> <span class="n">weights_distribution</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span> <span class="o">=</span> <span class="n">GaussianDistribution</span><span class="p">((</span><span class="n">output_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span> <span class="o">=</span> <span class="n">weights_distribution</span>

    <span class="c1"># Set bias distribution</span>
    <span class="k">if</span> <span class="n">bias_distribution</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span> <span class="o">=</span> <span class="n">GaussianDistribution</span><span class="p">((</span><span class="n">output_size</span><span class="p">,))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span> <span class="o">=</span> <span class="n">bias_distribution</span>

    <span class="c1"># Sample initial weights</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Register buffers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"weights"</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">"bias"</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.linear.Linear.forward"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.4.1.1</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span></code>
</h4>
<div class="doc doc-contents">
<p>This method is the forward pass of the layer.</p>
<p><span class="doc-section-title">Parameters:</span></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code>inputs</code>
</td>
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>input tensor. Dimensions: [batch, *].</p>
</div>
</td>
<td>
<em>required</em>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Raises:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="ValueError">ValueError</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Module has been frozen with undefined weights.</p>
</div>
</td>
</tr>
</tbody>
</table>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>outputs tensor. Dimensions: [batch, *].</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/linear.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    This method is the forward pass of the layer.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs: input tensor. Dimensions: [batch, *].</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: Module has been frozen with undefined weights.</span>

<span class="sd">    Returns:</span>
<span class="sd">        outputs tensor. Dimensions: [batch, *].</span>
<span class="sd">    """</span>

    <span class="c1"># Check if layer is frozen</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Module has been frozen with undefined weights"</span><span class="p">)</span>

    <span class="c1"># Compute outputs</span>
    <span class="c1"># pylint: disable=E1102</span>
    <span class="n">outputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.linear.Linear.freeze"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.4.1.2</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">freeze</span><span class="p">()</span></code>
</h4>
<div class="doc doc-contents">
<p>Freezes the current module and all submodules that are instances
of BayesianModule. Sets the frozen state to True.</p>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/linear.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
<span class="k">def</span><span class="w"> </span><span class="nf">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Freezes the current module and all submodules that are instances</span>
<span class="sd">    of BayesianModule. Sets the frozen state to True.</span>
<span class="sd">    """</span>

    <span class="c1"># Set indicator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">frozen</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Sample weights if they are undefined</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Sample bias is they are undefined</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>

    <span class="c1"># Detach weights and bias</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h4 class="doc doc-heading" id="illia.nn.torch.linear.Linear.kl_cost"><span class="enumerate-headings-plugin enumerate-heading-plugin">6.4.1.3</span> 
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code> <code class="highlight language-python"><span class="n">kl_cost</span><span class="p">()</span></code>
</h4>
<div class="doc doc-contents">
<p>Computes the Kullback-Leibler (KL) divergence cost for the
layer's weights and bias.</p>
<p><span class="doc-section-title">Returns:</span></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="doc-section-item">
<td>
<code><span title="torch.Tensor">Tensor</span></code>
</td>
<td>
<div class="doc-md-description">
<p>Tuple containing KL divergence cost and total number of</p>
</div>
</td>
</tr>
<tr class="doc-section-item">
<td>
<code><span title="int">int</span></code>
</td>
<td>
<div class="doc-md-description">
<p>parameters.</p>
</div>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>illia/nn/torch/linear.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">export</span>
<span class="k">def</span><span class="w"> </span><span class="nf">kl_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Computes the Kullback-Leibler (KL) divergence cost for the</span>
<span class="sd">    layer's weights and bias.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple containing KL divergence cost and total number of</span>
<span class="sd">        parameters.</span>
<span class="sd">    """</span>

    <span class="c1"># Compute log probs</span>
    <span class="n">log_probs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
    <span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="c1"># Compute the number of parameters</span>
    <span class="n">num_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_distribution</span><span class="o">.</span><span class="n">num_params</span><span class="p">()</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_distribution</span><span class="o">.</span><span class="n">num_params</span><span class="p">()</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">num_params</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<aside class="md-source-file">
<span class="md-source-file__fact">
<span class="md-icon" title="Last update">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"></path></svg>
</span>
<span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="August 29, 2025 11:54:03 UTC">August 29, 2025</span>
</span>
<span class="md-source-file__fact">
<span class="md-icon" title="Contributors">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 4a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 10c4.42 0 8 1.79 8 4v2H4v-2c0-2.21 3.58-4 8-4"></path></svg>
</span>
<nav>
      Daniel Bazo Correa
    </nav>
</span>
</aside>
</article>
</div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      © Telefonaktiebolaget LM Ericsson 1994-2025
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://www.linkedin.com/company/ericsson/" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://www.youtube.com/@ericsson" rel="noopener" target="_blank" title="www.youtube.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M549.7 124.1c-6.2-23.7-24.8-42.3-48.3-48.6C458.9 64 288.1 64 288.1 64S117.3 64 74.7 75.5c-23.5 6.3-42 24.9-48.3 48.6C15 167 15 256.4 15 256.4s0 89.4 11.4 132.3c6.3 23.6 24.8 41.5 48.3 47.8C117.3 448 288.1 448 288.1 448s170.8 0 213.4-11.5c23.5-6.3 42-24.2 48.3-47.8 11.4-42.9 11.4-132.3 11.4-132.3s0-89.4-11.4-132.3zM232.2 337.6V175.2l142.7 81.2z" fill="currentColor"></path></svg>
</a>
<a class="md-social__link" href="https://x.com/ericsson" rel="noopener" target="_blank" title="x.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M357.2 48h70.6L273.6 224.2 455 464H313L201.7 318.6 74.5 464H3.8l164.9-188.5L-5.2 48h145.6l100.5 132.9zm-24.8 373.8h39.1L119.1 88h-42z" fill="currentColor"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"base": "../../..", "features": ["content.tabs.link", "content.code.annotate", "content.code.copy", "content.tooltips", "announce.dismiss", "navigation.tabs", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.preview", "navigation.instant.progress", "navigation.sections", "navigation.top", "navigation.tracking", "navigation.indexes", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script>
<script src="../../../assets/javascripts/bundle.50899def.min.js"></script>
<script src="../../../javascripts/mathjax.js"></script>
<script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>