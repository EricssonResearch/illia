{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 13:47:06.519119: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-18 13:47:06.552340: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-18 13:47:06.552375: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-18 13:47:06.553109: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 13:47:06.559475: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-18 13:47:07.280933: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISTRIBUTIONS TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from illia.distributions.static.gaussian import GaussianDistribution as BackendAgnosticStaticGaussian\n",
    "from illia.distributions.dynamic.gaussian import GaussianDistribution as BackendAgnosticDynamicGaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take care of paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current working directory :{os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current sys path :{sys.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected_path= '/home/jovyan/illia/'\n",
    "expected_path=\"/mnt/c/Users/edanbaz/OneDrive - Ericsson/Documents/projects/illia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(expected_path):\n",
    "    raise Exception(\"Please ensure correct path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(expected_path,'examples'))\n",
    "print(f\"Changed working directory to :{os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if expected_path not in sys.path:\n",
    "    sys.path.insert(0, expected_path)\n",
    "    print(\"Added {expected_path} to sys.path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Updated sys.path : {sys.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "shape = (3, 2)\n",
    "mu_prior = 0.0\n",
    "std_prior = 0.1\n",
    "mu_init = 0.0\n",
    "rho_init = -7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_tensors(a, b, rtol=1e-1, atol=1e-1, name=\"\"):\n",
    "    are_close = np.allclose(a, b, rtol=rtol, atol=atol)\n",
    "    max_diff = np.max(np.abs(a - b))\n",
    "    print(f\"{name} are close: {are_close}\")\n",
    "    print(f\"Max absolute difference for {name}: {max_diff}\")\n",
    "    return are_close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize distributions\n",
    "torch_dist = BackendAgnosticDynamicGaussian(\n",
    "    shape=shape,\n",
    "    mu_init=mu_init, \n",
    "    rho_init=rho_init, \n",
    "    backend=\"torch\"\n",
    ")\n",
    "tf_dist = BackendAgnosticDynamicGaussian(\n",
    "    shape=shape,\n",
    "    mu_init=mu_init, \n",
    "    rho_init=rho_init, \n",
    "    backend=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 1 : sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Sampling\n",
    "print(\"Test 1: Sampling\")\n",
    "n_samples = 10000\n",
    "torch_samples = np.array([torch_dist.sample().detach().cpu().numpy() for _ in range(n_samples)])\n",
    "tf_samples = np.array([tf_dist.sample().numpy() for _ in range(n_samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare means\n",
    "torch_mean = np.mean(torch_samples, axis=0)\n",
    "tf_mean = np.mean(tf_samples, axis=0)\n",
    "compare_tensors(torch_mean, tf_mean, name=\"Means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare standard deviations\n",
    "torch_std = np.std(torch_samples, axis=0)\n",
    "tf_std = np.std(tf_samples, axis=0)\n",
    "compare_tensors(torch_std, tf_std, name=\"Standard deviations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 2: log probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Log probability\n",
    "print(\"\\nTest 2: Log probability\")\n",
    "x = np.random.randn(*shape).astype(np.float32)\n",
    "torch_log_prob = torch_dist.log_prob(torch.tensor(x, dtype=torch.float32)).detach().cpu().numpy()\n",
    "tf_log_prob = tf_dist.log_prob(tf.constant(x, dtype=tf.float32)).numpy()\n",
    "compare_tensors(torch_log_prob, tf_log_prob, rtol=1e-1, atol=1e-1, name=\"Log probabilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 3 : num of params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Number of parameters\n",
    "print(\"\\nTest 3: Number of parameters\")\n",
    "print(\"PyTorch num params:\", torch_dist.num_params)\n",
    "print(\"TensorFlow num params:\", tf_dist.num_params)\n",
    "print(\"Num params are equal:\", torch_dist.num_params == tf_dist.num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prove visually as well if implementations are correct or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(torch_samples.flatten(), bins=50, alpha=0.5, label='PyTorch')\n",
    "plt.hist(tf_samples.flatten(), bins=50, alpha=0.5, label='TensorFlow')\n",
    "plt.legend()\n",
    "plt.xlabel(\"values\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"Distribution of Samples\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(torch_samples.flatten()[:1000], tf_samples.flatten()[:1000], alpha=0.1)\n",
    "plt.plot([-3, 3], [-3, 3], 'r--')\n",
    "plt.xlabel(\"PyTorch Samples\")\n",
    "plt.ylabel(\"TensorFlow Samples\")\n",
    "plt.title(\"PyTorch vs TensorFlow Samples\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn-base.py or Bayesian Module TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from illia.nn.torch.base import BayesianModule as TorchBayesianModule\n",
    "from illia.nn.tf.base import BayesianModule as TFBayesianModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class definitions - forward method to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchTestModule(TorchBayesianModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def kl_cost(self):\n",
    "        return torch.tensor(1.0), 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFTestModule(TFBayesianModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = tf.keras.layers.Dense(5, activation=None)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def kl_cost(self):\n",
    "        return tf.constant(1.0), 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_module=TorchTestModule()\n",
    "\n",
    "tf_module=TFTestModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 1 : freeze and unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test freeze and unfreeze\n",
    "def test_freeze_unfreeze():\n",
    "    print(\"Testing freeze and unfreeze...\")\n",
    "    \n",
    "    # Test PyTorch module\n",
    "    assert not torch_module.frozen, \"PyTorch module should not be frozen initially\"\n",
    "    torch_module.freeze()\n",
    "    assert torch_module.frozen, \"PyTorch module should be frozen after freeze()\"\n",
    "    torch_module.unfreeze()\n",
    "    assert not torch_module.frozen, \"PyTorch module should not be frozen after unfreeze()\"\n",
    "\n",
    "    # Test TensorFlow module\n",
    "    assert not tf_module.frozen, \"TensorFlow module should not be frozen initially\"\n",
    "    tf_module.freeze()\n",
    "    assert tf_module.frozen, \"TensorFlow module should be frozen after freeze()\"\n",
    "    tf_module.unfreeze()\n",
    "    assert not tf_module.frozen, \"TensorFlow module should not be frozen after unfreeze()\"\n",
    "    \n",
    "    print(\"Freeze and unfreeze test passed!\",'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test2 : test kl cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kl_cost():\n",
    "    print(\"Testing kl_cost...\")\n",
    "    \n",
    "    torch_kl, torch_n = torch_module.kl_cost()\n",
    "    tf_kl, tf_n = tf_module.kl_cost()\n",
    "    print(f'PyTorch : {torch_kl.item()}, {torch_n}\\n')\n",
    "    print(f'TensorFlow : {tf_kl.numpy()}, {tf_n}\\n')\n",
    "    \n",
    "\n",
    "    assert torch_kl.item() == tf_kl.numpy(), f\"KL divergence mismatch: PyTorch {torch_kl.item()}, TensorFlow {tf_kl.numpy()}\"\n",
    "    assert torch_n == tf_n, f\"N mismatch: PyTorch {torch_n}, TensorFlow {tf_n}\"\n",
    "    \n",
    "    print(\"KL cost test passed!\",'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test 3 :Test forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_pass():\n",
    "    print(\"Testing forward pass...\")\n",
    "    \n",
    "    # random seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    # input data\n",
    "    input_data = np.random.randn(1, 10).astype(np.float32)\n",
    "    \n",
    "    # PyTorch forward pass\n",
    "    torch_input = torch.from_numpy(input_data)\n",
    "    torch_output = torch_module(torch_input)\n",
    "\n",
    "    # TensorFlow forward pass\n",
    "    tf_input = tf.convert_to_tensor(input_data)\n",
    "    tf_output = tf_module(tf_input)\n",
    "\n",
    "    # Compare outputs\n",
    "    torch_np = torch_output.detach().numpy()\n",
    "    tf_np = tf_output.numpy()\n",
    "    \n",
    "    max_diff = np.max(np.abs(torch_np - tf_np))\n",
    "    print(f\"Maximum absolute difference: {max_diff}\")\n",
    "    \n",
    "    if max_diff > 1e-1:\n",
    "        print(\"Warning-Ignore for now: Outputs differ slighlty,this might be due to different initialization or computational differences between PyTorch and TensorFlow for torch.nn.Linear && tf.keras.layers.Dense \")\n",
    "        print(\"PyTorch output:\", torch_np)\n",
    "        print(\"TensorFlow output:\", tf_np)\n",
    "    else:\n",
    "        print(\"Outputs are close enough.\")\n",
    "\n",
    "    # Use a more lenient comparison\n",
    "    np.testing.assert_allclose(torch_np, tf_np, rtol=1, atol=1)\n",
    "    \n",
    "    print(\"Forward pass test passed!\",'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run all test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_tests():\n",
    "    test_freeze_unfreeze()\n",
    "    test_kl_cost()\n",
    "    test_forward_pass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tests\n",
    "run_all_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn-losses.py or Bayesian Module TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'illia.nn.torch.linear' has no attribute 'Linear' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KLDivergenceLoss, ELBOLoss\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n",
      "File \u001b[0;32m/mnt/c/Users/edanbaz/OneDrive - Ericsson/Documents/projects/illia/illia/__init__.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn_geom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/Users/edanbaz/OneDrive - Ericsson/Documents/projects/illia/illia/nn_geom/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn_geom\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/mnt/c/Users/edanbaz/OneDrive - Ericsson/Documents/projects/illia/illia/nn_geom/conv/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn_geom\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcg_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CGConv\n",
      "File \u001b[0;32m/mnt/c/Users/edanbaz/OneDrive - Ericsson/Documents/projects/illia/illia/nn_geom/conv/cg_conv.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessagePassing\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adj, OptTensor, PairTensor\n",
      "File \u001b[0;32m/mnt/c/Users/edanbaz/OneDrive - Ericsson/Documents/projects/illia/illia/nn/torch/linear.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianModule\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01millia\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linear\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLinear\u001b[39;00m(\u001b[43mlinear\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m, BayesianModule):\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    This class is the Linear bayesian layer.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m        _description_\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     input_size: \u001b[38;5;28mint\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'illia.nn.torch.linear' has no attribute 'Linear' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from illia.nn.losses import KLDivergenceLoss, ELBOLoss\n",
    "from illia.nn.linear import Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_kl_divengence = KLDivergenceLoss(backend=\"tf\")\n",
    "tf_elbo_loss = ELBOLoss(loss_function=tf_kl_divengence, backend=\"tf\")\n",
    "\n",
    "torch_kl_divengence = KLDivergenceLoss(backend=\"torch\")\n",
    "torch_elbo_loss = ELBOLoss(loss_function=torch_kl_divengence, backend=\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# input data\n",
    "input_data = np.random.randn(1, 10).astype(np.float32)\n",
    "\n",
    "# PyTorch forward pass\n",
    "torch_input = torch.from_numpy(input_data)\n",
    "\n",
    "# TensorFlow forward pass\n",
    "tf_input = tf.convert_to_tensor(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from illia.nn.tf.base import BayesianModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFTestModule(tf.keras.Model, BayesianModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = tf.keras.layers.Dense(5, activation=None)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def kl_cost(self):\n",
    "        return tf.constant(1.0), 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchTestModule(TorchBayesianModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = Linear(input_size=10,output_size=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def kl_cost(self):\n",
    "        return torch.tensor(1.0), 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_module=TFTestModule()\n",
    "torch_module = TorchTestModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_module(tf_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_module.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_kl_divengence(tf_module).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dani",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
