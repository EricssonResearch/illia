{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Base Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from abc import abstractmethod\n",
    "from typing import Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_freeze_unfreeze():\n",
    "    \n",
    "    print(\"Testing freeze and unfreeze...\")\n",
    "    \n",
    "    # Test PyTorch module\n",
    "    assert not torch_module.frozen, \"PyTorch module should not be frozen initially\"\n",
    "    torch_module.freeze()\n",
    "\n",
    "    assert torch_module.frozen, \"PyTorch module should be frozen after freeze()\"\n",
    "    torch_module.unfreeze()\n",
    "\n",
    "    assert not torch_module.frozen, \"PyTorch module should not be frozen after unfreeze()\"\n",
    "\n",
    "    # Test TensorFlow module\n",
    "    assert not tf_module.frozen, \"TensorFlow module should not be frozen initially\"\n",
    "    tf_module.freeze()\n",
    "\n",
    "    assert tf_module.frozen, \"TensorFlow module should be frozen after freeze()\"\n",
    "    tf_module.unfreeze()\n",
    "\n",
    "    assert not tf_module.frozen, \"TensorFlow module should not be frozen after unfreeze()\"\n",
    "    \n",
    "    print(\"Freeze and unfreeze test passed!\",'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kl_cost():\n",
    "\n",
    "    print(\"Testing KL cost...\")\n",
    "    \n",
    "    torch_kl, torch_n = torch_module.kl_cost()\n",
    "    tf_kl, tf_n = tf_module.kl_cost()\n",
    "\n",
    "    print(f'\\nPyTorch : {torch_kl.item()}, {torch_n}')\n",
    "    print(f'TensorFlow : {tf_kl.numpy()}, {tf_n}\\n')\n",
    "\n",
    "    assert torch_kl.item() == tf_kl.numpy(), f\"KL divergence mismatch: PyTorch {torch_kl.item()}, TensorFlow {tf_kl.numpy()}\"\n",
    "    assert torch_n == tf_n, f\"N mismatch: PyTorch {torch_n}, TensorFlow {tf_n}\"\n",
    "    \n",
    "    print(\"KL cost test passed!\",'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_pass():\n",
    "\n",
    "    print(\"Testing forward pass...\")\n",
    "    \n",
    "    # Input data\n",
    "    input_data = np.random.randn(1, 10).astype(np.float32)\n",
    "    \n",
    "    # PyTorch forward pass\n",
    "    torch_input = torch.from_numpy(input_data)\n",
    "    torch_output = torch_module(torch_input)\n",
    "\n",
    "    # TensorFlow forward pass\n",
    "    tf_input = tf.convert_to_tensor(input_data)\n",
    "    tf_output = tf_module(tf_input)\n",
    "\n",
    "    # Compare outputs\n",
    "    torch_np = torch_output.detach().numpy()\n",
    "    tf_np = tf_output.numpy()\n",
    "    \n",
    "    max_diff = np.max(np.abs(torch_np - tf_np))\n",
    "    print(f\"Maximum absolute difference: {max_diff}\")\n",
    "    \n",
    "    if max_diff > 1e-1:\n",
    "        print(\"\"\"\n",
    "              Warning-Ignore for now: Outputs differ slighlty,this might be due to different \n",
    "              initialization or computational differences between PyTorch and TensorFlow for \n",
    "              torch.nn.Linear && tf.keras.layers.Dense \n",
    "              \"\"\"\n",
    "        )\n",
    "        print(\"PyTorch output:\", torch_np)\n",
    "        print(\"TensorFlow output:\", tf_np)\n",
    "    else:\n",
    "        print(\"Outputs are close enough.\")\n",
    "\n",
    "    # Use a more lenient comparison\n",
    "    np.testing.assert_allclose(torch_np, tf_np, rtol=1, atol=1)\n",
    "    \n",
    "    print(\"Forward pass test passed!\",'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_tests():\n",
    "    \n",
    "    test_freeze_unfreeze()\n",
    "    test_kl_cost()\n",
    "    test_forward_pass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the backend is selected we can import illia, if we want to change the backend we need to restart the kernel. The backend can't be changed dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import illia\n",
    "from illia.torch.nn.base import BayesianModule as TorchBayesianModule\n",
    "from illia.tf.nn.base import BayesianModule as TFBayesianModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the available backends using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illia.show_available_backends()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class definitions - forward method to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchTestModule(TorchBayesianModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def kl_cost(self):\n",
    "        return torch.tensor(1.0), 1\n",
    "    \n",
    "torch_module=TorchTestModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFTestModule(TFBayesianModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = tf.keras.layers.Dense(5)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def kl_cost(self):\n",
    "        return tf.constant(1.0), 1\n",
    "    \n",
    "tf_module=TFTestModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_tests()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
