{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian losses module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates the functionality of a Bayesian losses module. It covers basic operations such as checking trainable parameters and forward propagation of loss functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, you'll need to import some essential libraries. The specific libraries you use will depend on the backend you've chosen, such as PyTorch, TensorFlow, or Jax. Additionally, you'll need to import NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``check_parameters`` function verifies the existence of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_parameters():\n",
    "\n",
    "    print(\"Check the existence of trainable parameters in the classes...\")\n",
    "\n",
    "    torch_list_parameters = list(torch_module.parameters())\n",
    "    assert (\n",
    "        len(torch_list_parameters) != 0\n",
    "    ), \"No parameters availables in TorchTestModule\"\n",
    "\n",
    "    trainable_variables = tf_module.trainable_variables\n",
    "    assert (\n",
    "        len(trainable_variables) != 0\n",
    "    ), \"No trainable parameters available in TFTestModule\"\n",
    "\n",
    "    print(\"Test passed!\", \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``check_forward_losses`` function ensures that the loss functions produce consistent outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_forward_losses():\n",
    "\n",
    "    print(\"Check the forward propagation of the loss functions...\")\n",
    "\n",
    "    # Input data\n",
    "    input_data = np.random.randn(1, 10).astype(np.float32)\n",
    "    y_true = np.random.randn(1, 10).astype(np.float32)\n",
    "    y_pred = np.random.randn(1, 10).astype(np.float32)\n",
    "\n",
    "    # PyTorch forward pass\n",
    "    torch_input = torch.from_numpy(input_data)\n",
    "    torch_output = torch_module(torch_input)\n",
    "    torch_kl_divengence_output = torch_kl_divengence(torch_module)\n",
    "    torch_elbo_loss_output = torch_elbo_loss(\n",
    "        torch.from_numpy(y_true), torch.from_numpy(y_pred), torch_module\n",
    "    )\n",
    "\n",
    "    # Tensorflow forward pass\n",
    "    tf_input = tf.convert_to_tensor(input_data)\n",
    "    tf_output = tf_module(tf_input)\n",
    "    tf_kl_divergence_output = tf_kl_divengence(tf_module)\n",
    "    tf_elbo_loss_output = tf_elbo_loss(\n",
    "        tf.convert_to_tensor(y_true), tf.convert_to_tensor(y_pred), tf_module\n",
    "    )\n",
    "\n",
    "    # Assert that the outputs are similar\n",
    "    print(\"Torch output:\", torch_output)\n",
    "    print(\"TensorFlow output:\", tf_output)\n",
    "    print(\"Outputs are similar:\", np.allclose(torch_output.detach().numpy(), tf_output))\n",
    "\n",
    "    print(\"Torch KL divergence output:\", torch_kl_divengence_output)\n",
    "    print(\"TensorFlow KL divergence output:\", tf_kl_divergence_output)\n",
    "    print(\n",
    "        \"KL divergence outputs are similar:\",\n",
    "        np.allclose(\n",
    "            torch_kl_divengence_output.detach().numpy(), tf_kl_divergence_output\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    print(\"Torch ELBO loss output:\", torch_elbo_loss_output)\n",
    "    print(\"TensorFlow ELBO loss output:\", tf_elbo_loss_output)\n",
    "    print(\n",
    "        \"ELBO loss outputs are similar:\",\n",
    "        np.allclose(torch_elbo_loss_output.detach().numpy(), tf_elbo_loss_output),\n",
    "    )\n",
    "\n",
    "    print(\"Test passed!\", \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``run_all_tests`` function executes all test functions in sequence to validate the module's functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_tests():\n",
    "\n",
    "    check_parameters()\n",
    "    check_forward_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When setting the backend, we import the Illia library, which provides Bayesian module implementations. Note that backend selection requires a kernel restart and cannot be changed dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from illia.torch.nn.base import BayesianModule as TorchBayesianModule\n",
    "from illia.tf.nn.base import BayesianModule as TFBayesianModule\n",
    "from illia.torch.nn.losses import (\n",
    "    KLDivergenceLoss as TorchKLDivergenceLoss,\n",
    "    ELBOLoss as TorchELBOLoss,\n",
    ")\n",
    "from illia.torch.nn.linear import Linear as TorchLinear\n",
    "\n",
    "from illia.tf.nn.losses import (\n",
    "    KLDivergenceLoss as TFKLDivergenceLoss,\n",
    "    ELBOLoss as TFELBOLoss,\n",
    ")\n",
    "from illia.tf.nn.linear import Linear as TFLinear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define test classes implementing a simple linear layer and a method to compute KL divergence. These classes will be used in the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchTestModule(TorchBayesianModule):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = TorchLinear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.linear(x)\n",
    "\n",
    "    def kl_cost(self):\n",
    "\n",
    "        return torch.tensor(1.0), 1\n",
    "\n",
    "\n",
    "class TFTestModule(TFBayesianModule):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = TFLinear(10, 5)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        return self.linear(x)\n",
    "\n",
    "    def kl_cost(self):\n",
    "\n",
    "        return tf.constant(1.0), 1\n",
    "\n",
    "\n",
    "# PyTorch\n",
    "torch_kl_divengence = TorchKLDivergenceLoss()\n",
    "torch_elbo_loss = TorchELBOLoss(loss_function=torch.nn.MSELoss())\n",
    "torch_module = TorchTestModule()\n",
    "\n",
    "# Tensorflow\n",
    "tf_kl_divengence = TFKLDivergenceLoss()\n",
    "tf_elbo_loss = TFELBOLoss(loss_function=tf.keras.losses.MeanSquaredError())\n",
    "tf_module = TFTestModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run all tests to ensure that the module's functionalities work as expected across backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dani",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
