{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian base module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial explains the main features of a Bayesian base module. You'll learn how to perform essential tasks, including:\n",
    "\n",
    "+ Freezing and unfreezing layers: controlling which parts of the model are trainable.\n",
    "+ Calculating the KL divergence cost: measuring how much one probability distribution differs from a reference distribution.\n",
    "+ Performing a forward pass: processing input data through the model to get predictions.\n",
    "\n",
    "This guide is designed to help you understand these operations using Illia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, you'll need to import some essential libraries. The specific libraries you use will depend on the backend you've chosen, such as PyTorch, TensorFlow, or Jax. Additionally, you'll need to import NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `test_freeze_unfreeze` function confirms that layers can be accurately frozen and unfrozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_freeze_unfreeze():\n",
    "\n",
    "    print(\"Testing freeze and unfreeze...\")\n",
    "\n",
    "    # Test PyTorch module\n",
    "    assert not torch_module.frozen, \"PyTorch module should not be frozen initially\"\n",
    "    torch_module.freeze()\n",
    "\n",
    "    assert torch_module.frozen, \"PyTorch module should be frozen after freeze()\"\n",
    "    torch_module.unfreeze()\n",
    "\n",
    "    assert (\n",
    "        not torch_module.frozen\n",
    "    ), \"PyTorch module should not be frozen after unfreeze()\"\n",
    "\n",
    "    # Test TensorFlow module\n",
    "    assert not tf_module.frozen, \"TensorFlow module should not be frozen initially\"\n",
    "    tf_module.freeze()\n",
    "\n",
    "    assert tf_module.frozen, \"TensorFlow module should be frozen after freeze()\"\n",
    "    tf_module.unfreeze()\n",
    "\n",
    "    assert (\n",
    "        not tf_module.frozen\n",
    "    ), \"TensorFlow module should not be frozen after unfreeze()\"\n",
    "\n",
    "    print(\"Freeze and unfreeze test passed!\", \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``test_kl_cost`` function verifies the calculation of the KL divergence cost, ensuring that all frameworks yield consistent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kl_cost():\n",
    "\n",
    "    print(\"Testing KL cost...\")\n",
    "\n",
    "    torch_kl, torch_n = torch_module.kl_cost()\n",
    "    tf_kl, tf_n = tf_module.kl_cost()\n",
    "\n",
    "    print(f\"\\nPyTorch : {torch_kl.item()}, {torch_n}\")\n",
    "    print(f\"TensorFlow : {tf_kl.numpy()}, {tf_n}\\n\")\n",
    "\n",
    "    assert (\n",
    "        torch_kl.item() == tf_kl.numpy()\n",
    "    ), f\"KL divergence mismatch: PyTorch {torch_kl.item()}, TensorFlow {tf_kl.numpy()}\"\n",
    "    assert torch_n == tf_n, f\"N mismatch: PyTorch {torch_n}, TensorFlow {tf_n}\"\n",
    "\n",
    "    print(\"KL cost test passed!\", \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``test_forward_pass`` function ensures that the forward pass generates similar outputs across different framework models when provided with the same input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_pass():\n",
    "\n",
    "    print(\"Testing forward pass...\")\n",
    "\n",
    "    # Input data\n",
    "    input_data = np.random.randn(1, 10).astype(np.float32)\n",
    "\n",
    "    # PyTorch forward pass\n",
    "    torch_input = torch.from_numpy(input_data)\n",
    "    torch_output = torch_module(torch_input)\n",
    "\n",
    "    # TensorFlow forward pass\n",
    "    tf_input = tf.convert_to_tensor(input_data)\n",
    "    tf_output = tf_module(tf_input)\n",
    "\n",
    "    # Compare outputs\n",
    "    torch_np = torch_output.detach().numpy()\n",
    "    tf_np = tf_output.numpy()\n",
    "\n",
    "    max_diff = np.max(np.abs(torch_np - tf_np))\n",
    "    print(f\"Maximum absolute difference: {max_diff}\")\n",
    "\n",
    "    if max_diff > 1e-1:\n",
    "        print(\n",
    "            \"\"\"\n",
    "              Warning-Ignore for now: Outputs differ slighlty,this might be due to different \n",
    "              initialization or computational differences between PyTorch and TensorFlow for \n",
    "              torch.nn.Linear && tf.keras.layers.Dense \n",
    "              \"\"\"\n",
    "        )\n",
    "        print(\"PyTorch output:\", torch_np)\n",
    "        print(\"TensorFlow output:\", tf_np)\n",
    "    else:\n",
    "        print(\"Outputs are close enough.\")\n",
    "\n",
    "    # Use a more lenient comparison\n",
    "    np.testing.assert_allclose(torch_np, tf_np, rtol=1, atol=1)\n",
    "\n",
    "    print(\"Forward pass test passed!\", \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``run_all_tests`` function executes all test functions in sequence to validate the module's functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_tests():\n",
    "\n",
    "    test_freeze_unfreeze()\n",
    "    test_kl_cost()\n",
    "    test_forward_pass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seeds for reproducibility across different runs. This ensures that the results are consistent each time the code is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When setting the backend, we import the Illia library, which provides Bayesian module implementations. Note that backend selection requires a kernel restart and cannot be changed dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import illia\n",
    "from illia.torch.nn.base import BayesianModule as TorchBayesianModule\n",
    "from illia.tf.nn.base import BayesianModule as TFBayesianModule\n",
    "\n",
    "# Display available backends\n",
    "illia.show_available_backends()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test classes for various frameworks. Each class should implement a simple linear layer and include a method to calculate the KL divergence. These classes will be utilized in testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchTestModule(TorchBayesianModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def kl_cost(self):\n",
    "        return torch.tensor(1.0), 1\n",
    "\n",
    "\n",
    "class TFTestModule(TFBayesianModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = tf.keras.layers.Dense(5)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    def kl_cost(self):\n",
    "        return tf.constant(1.0), 1\n",
    "\n",
    "\n",
    "# PyTorch\n",
    "torch_module = TorchTestModule()\n",
    "\n",
    "# Tensorflow\n",
    "tf_module = TFTestModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run all tests to ensure that the module's functionalities work as expected across backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
